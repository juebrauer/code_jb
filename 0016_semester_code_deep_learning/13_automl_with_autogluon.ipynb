{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07adc0e3-7f49-414b-9e9b-2540aa0a5a69",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook gives a brief introduction to AutoML (Automated Machine Learning) using AutoGluon:\n",
    "\n",
    "https://auto.gluon.ai/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7362cb-7014-4a16-8011-ba48c9e5cc75",
   "metadata": {},
   "source": [
    "# TabularPredictor\n",
    "\n",
    "As an example we use this dataset:\n",
    "\n",
    "https://www.kaggle.com/datasets/mchilamwar/predict-concrete-strength\n",
    "\n",
    "and will try to predict, e.g., the strength of concrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216dc425-5323-4376-9c91-df1de7ac665c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juebrauer/miniconda3/envs/env_autogluon2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/juebrauer/.cache/kagglehub/datasets/mchilamwar/predict-concrete-strength/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mchilamwar/predict-concrete-strength\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9563b18-f976-46d2-82ae-d02bc8bc1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConcreteStrengthData.csv\n"
     ]
    }
   ],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8b7096-3db8-487e-a4af-46c6e2d8973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CementComponent</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAshComponent</th>\n",
       "      <th>WaterComponent</th>\n",
       "      <th>SuperplasticizerComponent</th>\n",
       "      <th>CoarseAggregateComponent</th>\n",
       "      <th>FineAggregateComponent</th>\n",
       "      <th>AgeInDays</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CementComponent   BlastFurnaceSlag  FlyAshComponent  WaterComponent  \\\n",
       "0                540.0               0.0              0.0           162.0   \n",
       "1                540.0               0.0              0.0           162.0   \n",
       "2                332.5             142.5              0.0           228.0   \n",
       "3                332.5             142.5              0.0           228.0   \n",
       "4                198.6             132.4              0.0           192.0   \n",
       "...                ...               ...              ...             ...   \n",
       "1025             276.4             116.0             90.3           179.6   \n",
       "1026             322.2               0.0            115.6           196.0   \n",
       "1027             148.5             139.4            108.6           192.7   \n",
       "1028             159.1             186.7              0.0           175.6   \n",
       "1029             260.9             100.5             78.3           200.6   \n",
       "\n",
       "      SuperplasticizerComponent  CoarseAggregateComponent  \\\n",
       "0                           2.5                    1040.0   \n",
       "1                           2.5                    1055.0   \n",
       "2                           0.0                     932.0   \n",
       "3                           0.0                     932.0   \n",
       "4                           0.0                     978.4   \n",
       "...                         ...                       ...   \n",
       "1025                        8.9                     870.1   \n",
       "1026                       10.4                     817.9   \n",
       "1027                        6.1                     892.4   \n",
       "1028                       11.3                     989.6   \n",
       "1029                        8.6                     864.5   \n",
       "\n",
       "      FineAggregateComponent  AgeInDays  Strength  \n",
       "0                      676.0         28     79.99  \n",
       "1                      676.0         28     61.89  \n",
       "2                      594.0        270     40.27  \n",
       "3                      594.0        365     41.05  \n",
       "4                      825.5        360     44.30  \n",
       "...                      ...        ...       ...  \n",
       "1025                   768.3         28     44.28  \n",
       "1026                   813.4         28     31.18  \n",
       "1027                   780.0         28     23.70  \n",
       "1028                   788.9         28     32.77  \n",
       "1029                   761.5         28     32.40  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv(path + \"/ConcreteStrengthData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43af278-4c4f-4e11-bf0d-7f90fdfdb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CementComponent            1030 non-null   float64\n",
      " 1   BlastFurnaceSlag           1030 non-null   float64\n",
      " 2   FlyAshComponent            1030 non-null   float64\n",
      " 3   WaterComponent             1030 non-null   float64\n",
      " 4   SuperplasticizerComponent  1030 non-null   float64\n",
      " 5   CoarseAggregateComponent   1030 non-null   float64\n",
      " 6   FineAggregateComponent     1030 non-null   float64\n",
      " 7   AgeInDays                  1030 non-null   int64  \n",
      " 8   Strength                   1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e69a72-af30-4566-80fa-4008f0c4dd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CementComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>281.167864</td>\n",
       "      <td>104.506364</td>\n",
       "      <td>102.00</td>\n",
       "      <td>192.375</td>\n",
       "      <td>272.900</td>\n",
       "      <td>350.000</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>142.950</td>\n",
       "      <td>359.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FlyAshComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>118.300</td>\n",
       "      <td>200.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WaterComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>121.80</td>\n",
       "      <td>164.900</td>\n",
       "      <td>185.000</td>\n",
       "      <td>192.000</td>\n",
       "      <td>247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuperplasticizerComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.400</td>\n",
       "      <td>10.200</td>\n",
       "      <td>32.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoarseAggregateComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>801.00</td>\n",
       "      <td>932.000</td>\n",
       "      <td>968.000</td>\n",
       "      <td>1029.400</td>\n",
       "      <td>1145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FineAggregateComponent</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>594.00</td>\n",
       "      <td>730.950</td>\n",
       "      <td>779.500</td>\n",
       "      <td>824.000</td>\n",
       "      <td>992.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AgeInDays</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>35.817961</td>\n",
       "      <td>16.705742</td>\n",
       "      <td>2.33</td>\n",
       "      <td>23.710</td>\n",
       "      <td>34.445</td>\n",
       "      <td>46.135</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count        mean         std     min      25%  \\\n",
       "CementComponent            1030.0  281.167864  104.506364  102.00  192.375   \n",
       "BlastFurnaceSlag           1030.0   73.895825   86.279342    0.00    0.000   \n",
       "FlyAshComponent            1030.0   54.188350   63.997004    0.00    0.000   \n",
       "WaterComponent             1030.0  181.567282   21.354219  121.80  164.900   \n",
       "SuperplasticizerComponent  1030.0    6.204660    5.973841    0.00    0.000   \n",
       "CoarseAggregateComponent   1030.0  972.918932   77.753954  801.00  932.000   \n",
       "FineAggregateComponent     1030.0  773.580485   80.175980  594.00  730.950   \n",
       "AgeInDays                  1030.0   45.662136   63.169912    1.00    7.000   \n",
       "Strength                   1030.0   35.817961   16.705742    2.33   23.710   \n",
       "\n",
       "                               50%       75%     max  \n",
       "CementComponent            272.900   350.000   540.0  \n",
       "BlastFurnaceSlag            22.000   142.950   359.4  \n",
       "FlyAshComponent              0.000   118.300   200.1  \n",
       "WaterComponent             185.000   192.000   247.0  \n",
       "SuperplasticizerComponent    6.400    10.200    32.2  \n",
       "CoarseAggregateComponent   968.000  1029.400  1145.0  \n",
       "FineAggregateComponent     779.500   824.000   992.6  \n",
       "AgeInDays                   28.000    56.000   365.0  \n",
       "Strength                    34.445    46.135    82.6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eddaa2f-8888-45f7-a4de-2909102718cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "df = df.sample(frac=1.0)\n",
    "\n",
    "# split data into training and test data\n",
    "N_train = int(len(df)*0.8)\n",
    "df.iloc[:N_train].to_csv(\"concrete_strength_train.csv\", index=False)\n",
    "df.iloc[N_train:].to_csv(\"concrete_strength_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ace09a-a391-4b29-b256-e5f28d515260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.13.11\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #37~24.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov 20 10:25:38 UTC 2\n",
      "CPU Count:          32\n",
      "Pytorch Version:    2.9.1+cu128\n",
      "CUDA Version:       12.8\n",
      "GPU Memory:         GPU 0: 11.60/11.60 GB\n",
      "Total GPU Memory:   Free: 11.60 GB, Allocated: 0.00 GB, Total: 11.60 GB\n",
      "GPU Count:          1\n",
      "Memory Avail:       21.21 GB / 31.03 GB (68.4%)\n",
      "Disk Space Avail:   14.85 GB / 195.80 GB (7.6%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='extreme'  : New in v1.5: The state-of-the-art for tabular data. Massively better than 'best' on datasets <100000 samples by using new Tabular Foundation Models (TFMs) meta-learned on https://tabarena.ai: TabPFNv2, TabICL, Mitra, TabDPT, and TabM. Requires a GPU and `pip install autogluon.tabular[tabarena]` to install TabPFN, TabICL, and TabDPT.\n",
      "\tpresets='best'     : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='best_v150': New in v1.5: Better quality than 'best' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='high'     : Strong accuracy with fast inference speed.\n",
      "\tpresets='high_v150': New in v1.5: Better quality than 'high' and 5x+ faster to train. Give it a try!\n",
      "\tpresets='good'     : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'   : Fast training time, ideal for initial prototyping.\n",
      "Loaded data from: concrete_strength_train.csv | Columns = 9 / 9 | Rows = 824 -> 824\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Beginning AutoGluon training ... Time limit = 240s\n",
      "AutoGluon will save models to \"/media/veracrypt1/09_src/code_jb/0016_semester_code_deep_learning/autogluon_concrete_strength_predictor\"\n",
      "Train Data Rows:    824\n",
      "Train Data Columns: 8\n",
      "Label Column:       Strength\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (81.75, 3.32, 35.72391, 16.74978)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21726.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 7 | ['CementComponent ', 'BlastFurnaceSlag', 'FlyAshComponent', 'WaterComponent', 'SuperplasticizerComponent', ...]\n",
      "\t\t('int', [])   : 1 | ['AgeInDays']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 7 | ['CementComponent ', 'BlastFurnaceSlag', 'FlyAshComponent', 'WaterComponent', 'SuperplasticizerComponent', ...]\n",
      "\t\t('int', [])   : 1 | ['AgeInDays']\n",
      "\t0.0s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_percentage_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 659, Val Rows: 165\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT ... Training model for up to 239.98s of the 239.98s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/21.2 GB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 26.7832\tvalid_set's mean_absolute_percentage_error: -0.117202\n",
      "[2000]\tvalid_set's l2: 24.9799\tvalid_set's mean_absolute_percentage_error: -0.109467\n",
      "[3000]\tvalid_set's l2: 24.3872\tvalid_set's mean_absolute_percentage_error: -0.106534\n",
      "[4000]\tvalid_set's l2: 24.4581\tvalid_set's mean_absolute_percentage_error: -0.106246\n",
      "[5000]\tvalid_set's l2: 24.6485\tvalid_set's mean_absolute_percentage_error: -0.106442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1059\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 236.85s of the 236.85s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/21.2 GB\n",
      "\t-0.1278\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 235.96s of the 235.96s of remaining time.\n",
      "\tFitting with cpus=32, gpus=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l2: 31.7302\tvalid_set's mean_absolute_percentage_error: -0.127854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.1575\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 235.33s of the 235.33s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t-0.1497\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 233.82s of the 233.82s of remaining time.\n",
      "\tFitting with cpus=32, gpus=0\n",
      "\t-0.1439\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 233.14s of the 233.14s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/20.9 GB\n",
      "Metric mean_absolute_percentage_error is not supported by this model - using mean_squared_error instead\n",
      "\t-0.1934\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 231.93s of the 231.93s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0\n",
      "\t-0.1333\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 230.88s of the 230.88s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.0/20.8 GB\n",
      "/home/juebrauer/miniconda3/envs/env_autogluon2/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py:975: FutureWarning: The parameter `force_int_remainder_cols` is deprecated and will be removed in 1.9. It has no effect. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "\t-0.108\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t49.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 181.69s of the 181.69s of remaining time.\n",
      "\tFitting with cpus=24, gpus=0, mem=0.1/20.8 GB\n",
      "\t-0.1371\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t2.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 239.98s of the 179.27s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=32, gpus=0, mem=0.0/20.8 GB\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t-0.0958\t = Validation score   (-mean_absolute_percentage_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.77s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 16181.7 rows/s (165 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/media/veracrypt1/09_src/code_jb/0016_semester_code_deep_learning/autogluon_concrete_strength_predictor\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "model = TabularPredictor(label=\"Strength\",\n",
    "                         eval_metric=\"mean_absolute_percentage_error\",\n",
    "                         path=\"autogluon_concrete_strength_predictor\")\n",
    "model = model.fit(\"concrete_strength_train.csv\", time_limit=4*60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc32ff4-e6b5-4305-8fc9-e735c30d6d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.095755</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>52.313040</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.032692</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-0.105948</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>3.097236</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>3.097236</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-0.107995</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>49.183112</td>\n",
       "      <td>0.004912</td>\n",
       "      <td>49.183112</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-0.127785</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.879704</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.879704</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-0.133300</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>1.035320</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>1.035320</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-0.137117</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>2.375581</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>2.375581</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-0.143915</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.580122</td>\n",
       "      <td>0.078691</td>\n",
       "      <td>0.580122</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-0.149661</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>1.508510</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>1.508510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-0.157530</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.532181</td>\n",
       "      <td>0.074089</td>\n",
       "      <td>0.532181</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-0.193401</td>\n",
       "      <td>mean_absolute_percentage_error</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>1.190964</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>1.190964</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val                     eval_metric  \\\n",
       "0  WeightedEnsemble_L2  -0.095755  mean_absolute_percentage_error   \n",
       "1           LightGBMXT  -0.105948  mean_absolute_percentage_error   \n",
       "2       NeuralNetTorch  -0.107995  mean_absolute_percentage_error   \n",
       "3             LightGBM  -0.127785  mean_absolute_percentage_error   \n",
       "4              XGBoost  -0.133300  mean_absolute_percentage_error   \n",
       "5        LightGBMLarge  -0.137117  mean_absolute_percentage_error   \n",
       "6        ExtraTreesMSE  -0.143915  mean_absolute_percentage_error   \n",
       "7             CatBoost  -0.149661  mean_absolute_percentage_error   \n",
       "8      RandomForestMSE  -0.157530  mean_absolute_percentage_error   \n",
       "9      NeuralNetFastAI  -0.193401  mean_absolute_percentage_error   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  \\\n",
       "0       0.010197  52.313040                0.000382           0.032692   \n",
       "1       0.004902   3.097236                0.004902           3.097236   \n",
       "2       0.004912  49.183112                0.004912          49.183112   \n",
       "3       0.001317   0.879704                0.001317           0.879704   \n",
       "4       0.002702   1.035320                0.002702           1.035320   \n",
       "5       0.001605   2.375581                0.001605           2.375581   \n",
       "6       0.078691   0.580122                0.078691           0.580122   \n",
       "7       0.001199   1.508510                0.001199           1.508510   \n",
       "8       0.074089   0.532181                0.074089           0.532181   \n",
       "9       0.008361   1.190964                0.008361           1.190964   \n",
       "\n",
       "   stack_level  can_infer  fit_order  \n",
       "0            2       True         10  \n",
       "1            1       True          1  \n",
       "2            1       True          8  \n",
       "3            1       True          2  \n",
       "4            1       True          7  \n",
       "5            1       True          9  \n",
       "6            1       True          5  \n",
       "7            1       True          4  \n",
       "8            1       True          3  \n",
       "9            1       True          6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ba662e-9605-4c30-933d-3eea16b3c550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.leaderboard())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d5c140-e32d-477b-9f23-8516beba04c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new predictions!\n",
    "from autogluon.tabular import TabularPredictor\n",
    "model = TabularPredictor.load(\"autogluon_concrete_strength_predictor\")\n",
    "\n",
    "import pandas\n",
    "df_test = pandas.read_csv(\"concrete_strength_test.csv\")\n",
    "\n",
    "df_test[\"preds\"] = model.predict(df_test)\n",
    "df_test.to_csv(\"data_with_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d71e32-3945-4ce3-8cd6-bb44d5f9ae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      52.309258\n",
       "1      80.203018\n",
       "2      13.280212\n",
       "3      41.483154\n",
       "4      43.198029\n",
       "         ...    \n",
       "201     9.801093\n",
       "202    32.864487\n",
       "203    43.014103\n",
       "204    37.632629\n",
       "205    26.504713\n",
       "Name: Strength, Length: 206, dtype: float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d764d91-01d2-4796-aeb3-161bf3747ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e0ab4a-23a6-46dc-9011-24e31d8e9b45",
   "metadata": {},
   "source": [
    "# TimeSeriesPredictor\n",
    "\n",
    "We will do a forecast for bike sharing in London.\n",
    "\n",
    "Dataset:\n",
    "\n",
    "https://www.kaggle.com/datasets/hmavrodiev/london-bike-sharing-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21245a0d-17ed-49c3-8915-ab865352112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"hmavrodiev/london-bike-sharing-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a2ac7-9680-42b5-9c6c-4d7533fddd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247d7c6-8806-40cc-b74f-02b0fde480c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv(path + \"/london_merged.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a43b1-a365-46a0-8ea2-4065bf4e28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fb44e-b124-462c-b23a-3a7847a557f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pandas.to_datetime(df['timestamp'])\n",
    "df = df.set_index(\"timestamp\", drop=False)\n",
    "\n",
    "# We need to have an \"time series ID (item id)\" column in AutoGluon\n",
    "# AutoGluon needs this in order to differ between the time series\n",
    "df['series_id'] = 'London'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02ab89-129a-4063-b9b2-cfd1d60ad1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eaf0c6-1210-4f16-93e2-4cc582b3accc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39d6e3-e9c4-4718-8a14-dfe53dee4539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6794bc-e6a7-4dba-b16c-52aa1da3302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train period\n",
    "df.loc[\"2015-01\" : \"2016-09\"].to_csv(\"london_bikes_train.csv\", index=False)\n",
    "\n",
    "# prepare test period / ground truth data to compare forecast with\n",
    "df.loc[\"2016-10-01\" : \"2016-10-14\"].to_csv(\"london_bikes_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e961e-cec7-4d6f-9acf-6023eba8be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    \"london_bikes_train.csv\",\n",
    "    id_column=\"series_id\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")\n",
    "\n",
    "model = TimeSeriesPredictor(\n",
    "    prediction_length=48,  # Predict the next 48 hours\n",
    "    target=\"cnt\",\n",
    "    eval_metric=\"MASE\",\n",
    "    freq='h',  # <--- Explicitly tell it \"This is Hourly data\"\n",
    "    path=\"autogluon_london_bikesharing_predictor\"\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_data,\n",
    "    presets=\"best_quality\",\n",
    "    time_limit=6*60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59488281-6ade-4b10-84b6-9cbbb4c53630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Reload model\n",
    "path = \"autogluon_london_bikesharing_predictor\"\n",
    "model = TimeSeriesPredictor.load(path)\n",
    "print(model.model_names())\n",
    "\n",
    "# 2. Read in data for which to do a forecast\n",
    "df = pandas.read_csv(\"london_bikes_train.csv\")\n",
    "df['timestamp'] = pandas.to_datetime(df['timestamp'])\n",
    "df = df.set_index(\"timestamp\", drop=False)\n",
    "df[\"series_id\"] = \"London\"\n",
    "input_timeseries = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"series_id\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 3. Read in ground truth data\n",
    "df_gt = pandas.read_csv(\"london_bikes_test.csv\")\n",
    "df_gt['timestamp'] = pandas.to_datetime(df_gt['timestamp'])\n",
    "df_gt = df_gt.set_index(\"timestamp\", drop=False)\n",
    "gt_data = df_gt.iloc[:48]\n",
    "\n",
    "# 4. Predict / Forecast with the best model\n",
    "preds = model.predict( input_timeseries )\n",
    "\n",
    "# 5. Visualize ground truth vs. predictions\n",
    "plt.plot(gt_data[\"cnt\"], color=\"black\")\n",
    "plt.plot(preds[\"mean\"][\"London\"], color=\"red\", linestyle=\"--\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d91e3c-3863-434d-9728-9c78613893ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd190b-a4d7-448c-a6fe-1a00e28772ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use AutoGluon's prediction visualization function\n",
    "import matplotlib.pyplot as plt\n",
    "model.plot(data=input_timeseries, predictions=preds, item_ids=['London'], max_history_length=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e552b-6702-4015-a071-0fc4a88bc48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaaedf9-3901-4533-8e4a-f5d67031d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model.model_names():\n",
    "\n",
    "    # Predict / Forecast with specific model\n",
    "    preds = model.predict( input_timeseries, model=model_name )\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(gt_data[\"cnt\"], color=\"black\")\n",
    "    plt.plot(preds[\"mean\"][\"London\"], color=\"red\", linestyle=\"--\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"Predictions of model {model_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bd9b9-b797-4af2-a5e8-94de68fd396e",
   "metadata": {},
   "source": [
    "# Decompose time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a574ed-af3b-4ede-9280-3a63c386bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive time series decomposition with visualization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to use statsmodels; if unavailable, fall back to a simple manual additive decomposition\n",
    "try:\n",
    "    from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "    HAVE_SM = True\n",
    "except Exception:\n",
    "    HAVE_SM = False\n",
    "\n",
    "print(HAVE_SM)\n",
    "\n",
    "# 1. Generate synthetic time series (5 years)\n",
    "rng = pd.date_range(\"2020-01-01\", periods=5*12, freq=\"MS\")\n",
    "np.random.seed(42)\n",
    "\n",
    "trend = np.linspace(10, 22, len(rng))  # linearer Trend\n",
    "seasonal_true = 2*np.sin(2*np.pi * (rng.month-1)/12)  # jährliche Saisonalität\n",
    "noise = np.random.normal(0, 0.8, len(rng))\n",
    "\n",
    "y = trend + seasonal_true + noise\n",
    "ts = pd.Series(y, index=rng, name=\"Beispielreihe\")\n",
    "\n",
    "# 2. Decompose with additived model\n",
    "if HAVE_SM:\n",
    "    decomp = seasonal_decompose(ts, model=\"additive\", period=12, extrapolate_trend=\"freq\")\n",
    "    observed = decomp.observed\n",
    "    trend_est = decomp.trend\n",
    "    seasonal_est = decomp.seasonal\n",
    "    resid = decomp.resid\n",
    "else:\n",
    "    # Trend: moving average with window=12 (months), centered\n",
    "    trend_est = ts.rolling(window=12, center=True, min_periods=6).mean()\n",
    "    # Detrend\n",
    "    detrended = ts - trend_est\n",
    "    # Seasonal component: mean per month (and all years), map to index\n",
    "    month_avgs = detrended.groupby(detrended.index.month).mean()\n",
    "    seasonal_est = ts.index.month.map(month_avgs).to_series(index=ts.index)\n",
    "    # Residuals\n",
    "    resid = ts - trend_est - seasonal_est\n",
    "    observed = ts\n",
    "\n",
    "# 3. Visualization helper function\n",
    "def make_plot(series, title, ylabel):\n",
    "    plt.figure(figsize=(10, 3.2))\n",
    "    plt.plot(series.index, series.values)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Datum\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "make_plot(observed, \"Observed\", \"value\")\n",
    "make_plot(trend_est, \"Trend (additive)\", \"value\")\n",
    "make_plot(seasonal_est, \"Seasonality\", \"value\")\n",
    "make_plot(resid, \"Residuals\", \"value\")\n",
    "make_plot(trend_est + seasonal_est + resid, \"Time series as addition of components\", \"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5737894e-af11-4995-a0cc-622e77504b6a",
   "metadata": {},
   "source": [
    "# Covariates\n",
    "\n",
    "- In AutoGluon TimeSeriesPredictor, covariates are extra variables that help predict the target time series.\n",
    "- They provide additional context beyond past target values.\n",
    "- There are three main types of covariates.\n",
    "    - Past covariates are known only up to the current time (e.g., past demand or sensor data).\n",
    "    - Known (future) covariates are available in advance, including the forecast horizon (e.g., holidays or planned promotions).\n",
    "    - Static covariates do not change over time and describe each series (e.g., store location or product category).\n",
    "- Covariates help models learn seasonality and external effects.\n",
    "- They improve accuracy, especially for longer forecasts.\n",
    "- Only use covariates that are truly available at prediction time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97f8bb7-76bb-40cd-b206-dec9cf7074a3",
   "metadata": {},
   "source": [
    "## Generate train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535246f-1ca3-44ca-9064-be7ba0c41ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# We will simulate N days\n",
    "N = 2*365\n",
    "dates = pd.date_range(\"2026-01-01\", periods=N, freq=\"D\")\n",
    "\n",
    "# We will simulate two time series\n",
    "time_series_ids = [\"A\", \"B\"]\n",
    "\n",
    "# Simulate two time series\n",
    "rows = []\n",
    "    \n",
    "# Simulate each day\n",
    "for t, ts in enumerate(dates):\n",
    "\n",
    "    for time_series_id in time_series_ids:\n",
    "\n",
    "        # Give the time series a different y-intercept\n",
    "        if time_series_id == \"A\":\n",
    "            base = 50\n",
    "            seasonality = 7\n",
    "        elif time_series_id == \"B\":\n",
    "            base = 80\n",
    "            seasonality = 14\n",
    "    \n",
    "    \n",
    "        # simulate time series value with weekly seasonality\n",
    "        y = base + 10*np.sin(2*np.pi*t/seasonality) + rng.normal(0, 2)\n",
    "    \n",
    "        # simulate past covariate: temperature (yearly seasonality)\n",
    "        # The temperatur will not be known for the forecast horizon!\n",
    "        temp = 15 + 8*np.sin(2*np.pi*t/365) + rng.normal(0, 1)\n",
    "    \n",
    "        # simulate known covariates: DayOfWeek (dow), Weekend (is_weekend)\n",
    "        # This will be known in advance for the forecast horizon\n",
    "        dow = ts.dayofweek\n",
    "        is_weekend = int(dow >= 5)\n",
    "    \n",
    "        # New data row for our table to be created\n",
    "        rows.append(\n",
    "            {\"series_id\": time_series_id,\n",
    "             \"timestamp\": ts,\n",
    "             \"target\": y,\n",
    "             \"temp\": temp,\n",
    "             \"day_of_week\": dow,\n",
    "              \"is_weekend\": is_weekend}\n",
    "        )\n",
    "\n",
    "# create table\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# split into train und test data\n",
    "# save training data\n",
    "df.iloc[:N//2].to_csv(\"timeseries_train.csv\", index=False)\n",
    "# save test data\n",
    "df.iloc[N//2:].to_csv(\"timeseries_test.csv\", index=False)\n",
    "\n",
    "# plot start of training data\n",
    "import matplotlib.pyplot as plt\n",
    "df_A = df.query(\"series_id=='A'\").head(200)\n",
    "df_B = df.query(\"series_id=='B'\").head(200)\n",
    "plt.plot(df_A[\"timestamp\"], df_A[\"target\"], color=\"black\", label=\"A\" )\n",
    "plt.plot(df_B[\"timestamp\"], df_B[\"target\"], color=\"green\", label=\"B\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7007388-31f3-47d8-b87a-7b71ae825c27",
   "metadata": {},
   "source": [
    "## Train the time series predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd37a8-f8ea-4411-a56e-d375c077fc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, re-read the training data to prepare for training\n",
    "import pandas\n",
    "df_train = pandas.read_csv(\"timeseries_train.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "# This is mandatory in order to use the TimeSeriesPredictor\n",
    "ts_train = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_train,\n",
    "    id_column=\"series_id\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")\n",
    "\n",
    "\n",
    "# Now, let us train a time series predictor\n",
    "prediction_length = 28\n",
    "\n",
    "model = TimeSeriesPredictor(\n",
    "    path=\"autogluon_ts_predictor_using_covariates\",\n",
    "    target=\"target\",\n",
    "    prediction_length=prediction_length,\n",
    "    freq=\"D\",\n",
    "    known_covariates_names=[\"day_of_week\", \"is_weekend\"],\n",
    ")\n",
    "\n",
    "# \"temp\" will be automatically detected as \"past covariate\"\n",
    "# since it is not a target and not a known covariate\n",
    "model.fit(\n",
    "    train_data=ts_train,\n",
    "    presets=\"medium_quality\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5416b96-f6ec-4d7f-b06c-aa2e363492b9",
   "metadata": {},
   "source": [
    "## Use time series predictor with known covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42620764-8e72-4e58-b0ca-99b8ab21911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "\n",
    "prediction_length = 28\n",
    "path = \"autogluon_ts_predictor_using_covariates\"\n",
    "model = TimeSeriesPredictor.load(path)\n",
    "\n",
    "# History: training data\n",
    "df_train = pd.read_csv(\"timeseries_train.csv\", parse_dates=[\"timestamp\"])\n",
    "ts_train = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_train, id_column=\"series_id\", timestamp_column=\"timestamp\"\n",
    ")\n",
    "\n",
    "# 1) Create the EXACT future index AutoGluon needs (per series)\n",
    "future_known = model.make_future_data_frame(ts_train)\n",
    "\n",
    "# 2) Fill known covariates for that future index\n",
    "# future_known is a TimeSeriesDataFrame with correct (item_id, timestamp)\n",
    "# Convert to pandas to compute features easily\n",
    "fk = future_known.reset_index()  # columns: item_id, timestamp, ...\n",
    "fk[\"day_of_week\"] = fk[\"timestamp\"].dt.dayofweek\n",
    "fk[\"is_weekend\"] = (fk[\"day_of_week\"] >= 5).astype(int)\n",
    "\n",
    "# Keep required columns + rename item_id back to your id column if you want (not necessary)\n",
    "future_known_covariates = TimeSeriesDataFrame.from_data_frame(\n",
    "    fk[[\"item_id\", \"timestamp\", \"day_of_week\", \"is_weekend\"]],\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    ")\n",
    "\n",
    "# 3) Predict\n",
    "preds = model.predict(ts_train, known_covariates=future_known_covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583831d-b997-4b6a-8697-970aef9cfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_known.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e5ddd-7539-4112-a8a7-d6ae1c600570",
   "metadata": {},
   "outputs": [],
   "source": [
    "fk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6442af-03e7-413a-aab0-77a3579cc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_known_covariates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a72d2-93c7-4aa3-b4e1-aa127af7f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa62e06b-18b9-44cd-8e69-3addc550806b",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b877a15-3241-4c18-9138-133864681bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot helper ---\n",
    "def plot_series(item_id: str, history_days: int = 120, lo_q=\"0.1\", hi_q=\"0.9\"):\n",
    "    # history tail\n",
    "    hist = ts_train.loc[item_id].reset_index()  # timestamp, target, ...\n",
    "    hist_tail = hist.tail(history_days)\n",
    "\n",
    "    # forecast\n",
    "    fcst = preds.loc[item_id].reset_index()  # timestamp, mean, 0.1, 0.9, ...\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(hist_tail[\"timestamp\"], hist_tail[\"target\"], label=f\"{item_id} history\")\n",
    "    plt.plot(fcst[\"timestamp\"], fcst[\"mean\"], label=f\"{item_id} forecast (mean)\")\n",
    "\n",
    "    # Optional: prediction interval if quantile columns exist\n",
    "    if lo_q in fcst.columns and hi_q in fcst.columns:\n",
    "        plt.fill_between(fcst[\"timestamp\"], fcst[lo_q], fcst[hi_q], alpha=0.2, label=f\"PI [{lo_q}, {hi_q}]\")\n",
    "\n",
    "    plt.axvline(hist_tail[\"timestamp\"].iloc[-1], linestyle=\"--\", label=\"train end\")\n",
    "    plt.title(f\"Series {item_id}: history + {prediction_length}-day forecast\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Plot A and B ---\n",
    "plot_series(\"A\", history_days=120)\n",
    "plot_series(\"B\", history_days=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f48c9d-4d03-4a53-9208-9b817ec9b6e9",
   "metadata": {},
   "source": [
    "# TimeSeriesPredictor predicts quantiles\n",
    "\n",
    "Quantile prediction means that a model forecasts a range of possible future values, not just a single number.\n",
    "\n",
    "A quantile answers the question: “Below which value will the target fall with probability q?”\n",
    "\n",
    "For example, the 0.1 quantile means there is a 10 % chance the true value will be below that \n",
    "number.\n",
    "\n",
    "The 0.5 quantile (median) splits the uncertainty in half: the outcome is equally likely to be above or below it.\n",
    "This is often more robust than the mean when forecasts are skewed.\n",
    "\n",
    "A 0.9 quantile means there is a 90 % chance the true value will be below that value.\n",
    "Only 10 % of outcomes are expected to exceed it.\n",
    "\n",
    "The interval between two quantiles (for example 0.1 and 0.9) forms a prediction interval.\n",
    "In this case, the model expects the true value to lie inside that band 80 % of the time.\n",
    "\n",
    "If the interval is wide, the model is uncertain; if it is narrow, the model is confident.\n",
    "\n",
    "Quantile forecasts are especially useful when decision-making must account for risk.\n",
    "\n",
    "They allow planners to choose conservative, average, or aggressive strategies based on different quantiles.\n",
    "\n",
    "In short, quantile prediction turns forecasting into probabilistic decision support rather than a single-point guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc465f-11a0-4101-986f-e4d4af745f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
