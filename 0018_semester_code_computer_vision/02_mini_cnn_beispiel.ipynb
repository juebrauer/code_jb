{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9a3e36",
   "metadata": {},
   "source": [
    "# Komplettes Skript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa7cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=1.8255 acc=0.298 | test_loss=1.6096 acc=0.384\n",
      "Epoch 02 | train_loss=1.5282 acc=0.428 | test_loss=1.4053 acc=0.485\n",
      "Epoch 03 | train_loss=1.3554 acc=0.507 | test_loss=1.2984 acc=0.540\n",
      "Epoch 04 | train_loss=1.2186 acc=0.560 | test_loss=1.1459 acc=0.584\n",
      "Epoch 05 | train_loss=1.1229 acc=0.598 | test_loss=1.1268 acc=0.602\n",
      "Epoch 06 | train_loss=1.0619 acc=0.620 | test_loss=1.0496 acc=0.629\n",
      "Epoch 07 | train_loss=1.0128 acc=0.638 | test_loss=1.0087 acc=0.642\n",
      "Epoch 08 | train_loss=0.9681 acc=0.656 | test_loss=1.0544 acc=0.624\n",
      "Epoch 09 | train_loss=0.9297 acc=0.672 | test_loss=0.9786 acc=0.652\n",
      "Epoch 10 | train_loss=0.8881 acc=0.684 | test_loss=0.8811 acc=0.689\n",
      "Epoch 11 | train_loss=0.8521 acc=0.698 | test_loss=0.8724 acc=0.691\n",
      "Epoch 12 | train_loss=0.8185 acc=0.712 | test_loss=0.9134 acc=0.682\n",
      "Epoch 13 | train_loss=0.8019 acc=0.717 | test_loss=0.8620 acc=0.702\n",
      "Epoch 14 | train_loss=0.7662 acc=0.730 | test_loss=0.8321 acc=0.717\n",
      "Epoch 15 | train_loss=0.7409 acc=0.739 | test_loss=0.7621 acc=0.737\n",
      "Saved to small_cifar10_cnn.pt\n"
     ]
    }
   ],
   "source": [
    "# mini_cifar10_cnn.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ---- Setup ----\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# CIFAR-10: 32x32 RGB, Klassen=10\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                         std=(0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                         std=(0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_ds = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_ds  = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=1, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False, num_workers=1, pin_memory=True)\n",
    "\n",
    "# ---- Kleines CNN ----\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)   # 32x32 -> 32x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)  # 32x32 -> 32x32\n",
    "        self.pool  = nn.MaxPool2d(2, 2)               # 32x32 -> 16x16\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # 16x16 -> 16x16\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)# 16x16 -> 16x16\n",
    "        self.head  = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),                  # -> 128x1x1\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = SmallCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 15\n",
    "\n",
    "# ---- Training ----\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # ---- Evaluation ----\n",
    "    model.eval()\n",
    "    correct, total, test_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            test_loss += loss.item() * imgs.size(0)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss /= total\n",
    "    test_acc = correct / total\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} acc={train_acc:.3f} | \"\n",
    "          f\"test_loss={test_loss:.4f} acc={test_acc:.3f}\")\n",
    "\n",
    "# Optional: Modell speichern\n",
    "torch.save(model.state_dict(), \"small_cifar10_cnn.pt\")\n",
    "print(\"Saved to small_cifar10_cnn.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2da7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
